{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import config\n",
    "import torch\n",
    "import numpy as np\n",
    "from autoencoder import ConvDecoder, ConvEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "# from lshash import LSHash\n",
    "from lshash.lshash import LSHash\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATH = \"/Users/abhishekvaidyanathan/Downloads/geological_similarity/schist/ZZ5Z5.jpg\"\n",
    "NUM_IMAGES = 10\n",
    "ENCODER_MODEL_PATH = \"geological_encoding.pt\"\n",
    "EMBEDDING_PATH = \"geological_embed.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/abhishekvaidyanathan/Downloads/geological_similarity/'\n",
    "image_files = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        image_files.append(os.path.join(subdir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_tensor(image_path, device):\n",
    "    image_tensor = T.ToTensor()(Image.open(image_path))\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    print(image_tensor.shape)\n",
    "    # input_images = image_tensor.to(device)\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similar_images(image_path, num_images, embedding, device):\n",
    "    image_tensor = load_image_tensor(image_path, device)\n",
    "    # image_tensor = image_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_embedding = encoder(image_tensor).cpu().detach().numpy()\n",
    "\n",
    "    print(image_embedding.shape)\n",
    "\n",
    "    flattened_embedding = image_embedding.reshape((image_embedding.shape[0], -1))\n",
    "    print(\"flattened embedding\")\n",
    "    print(flattened_embedding.shape)\n",
    "\n",
    "    k = 1 # hash size\n",
    "    L = 5  # number of tables\n",
    "    d = flattened_embedding.shape[1] # Dimension of Feature vector\n",
    "    lsh = LSHash(hash_size=k, input_dim=d, num_hashtables=L)\n",
    "    # LSH on all the images\n",
    "    # for img_path, vec in tqdm_notebook(feature_dict.items()):\n",
    "    lsh.index(flattened_embedding, extra_data=image_path)\n",
    "    print(lsh.index)\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=num_images, metric=\"cosine\")\n",
    "    knn.fit(embedding)\n",
    "\n",
    "    _, indices = knn.kneighbors(flattened_embedding)\n",
    "    indices_list = indices.tolist()\n",
    "    #print(indices_list)\n",
    "    return indices_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similar_images(indices_list):\n",
    "    indices = indices_list[0]\n",
    "    print(\"total indices: \", len(indices))\n",
    "    print(indices_list)\n",
    "    for index in indices:\n",
    "        # img_name = str(index - 1) + \".jpg\"\n",
    "        # print(img_name)\n",
    "        img_path = image_files[index]\n",
    "        print(img_path)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 28, 28])\n",
      "(1, 64, 3, 3)\n",
      "flattened embedding\n",
      "(1, 576)\n",
      "The input point needs to be of the same dimension as\n",
      "                  `input_dim` when initializing this LSHash instance shapes (1,576) and (1,576) not aligned: 576 (dim 1) != 1 (dim 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,576) and (1,576) not aligned: 576 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-eb96d17fc05e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mindices_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_similar_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_IMAGE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_IMAGES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplot_similar_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-fad7b9c73e35>\u001b[0m in \u001b[0;36mcompute_similar_images\u001b[0;34m(image_path, num_images, embedding, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# LSH on all the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# for img_path, vec in tqdm_notebook(feature_dict.items()):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/lshash/lshash.py\u001b[0m in \u001b[0;36mindex\u001b[0;34m(self, input_point, extra_data)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash_tables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             table.append_val(self._hash(self.uniform_planes[i], input_point),\n\u001b[0m\u001b[1;32m    225\u001b[0m                              value)\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/lshash/lshash.py\u001b[0m in \u001b[0;36m_hash\u001b[0;34m(self, planes, input_point)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0minput_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_point\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for faster dot product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mprojections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             print(\"\"\"The input point needs to be an array-like object with\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,576) and (1,576) not aligned: 576 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "encoder = ConvEncoder()\n",
    "\n",
    "# Load the state dict of encoder\n",
    "encoder.load_state_dict(torch.load(ENCODER_MODEL_PATH, map_location=device))\n",
    "encoder.eval()\n",
    "encoder.to(device)\n",
    "\n",
    "# Loads the embedding\n",
    "embedding = np.load(EMBEDDING_PATH)\n",
    "test_img = Image.open(TEST_IMAGE_PATH).convert(\"RGB\")\n",
    "plt.imshow(test_img)\n",
    "plt.show()\n",
    "indices_list = compute_similar_images(TEST_IMAGE_PATH, NUM_IMAGES, embedding, device)\n",
    "plot_similar_images(indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbits = 128  # number of hyperplanes and binary vals to produce\n",
    "d = 12  # vector dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17663986, -0.47515665, -0.25475753, ..., -0.34984148,\n",
       "         0.43382567,  0.25103632],\n",
       "       [-0.2082735 ,  0.43248968, -0.03093244, ...,  0.10211122,\n",
       "         0.46370967,  0.09459642],\n",
       "       [-0.2090817 , -0.36018824,  0.09016499, ..., -0.39382654,\n",
       "        -0.42365891, -0.37993116],\n",
       "       ...,\n",
       "       [-0.15645204,  0.46213432,  0.30721646, ...,  0.33493608,\n",
       "         0.07621659,  0.07090659],\n",
       "       [-0.24802427,  0.18376989, -0.10687889, ..., -0.31694203,\n",
       "        -0.14463738,  0.38073999],\n",
       "       [-0.04128877,  0.07768719, -0.05390441, ...,  0.00559373,\n",
       "        -0.16155653,  0.39817165]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# create a set of 4 hyperplanes, with 2 dimensions\n",
    "plane_norms = np.random.rand(nbits, d) - .5\n",
    "plane_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray([1, 2])\n",
    "b = np.asarray([2, 1])\n",
    "c = np.asarray([3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.73417344, -0.50327018,  0.86757322,  0.69679384])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dot = np.dot(a, plane_norms.T)\n",
    "b_dot = np.dot(b, plane_norms.T)\n",
    "c_dot = np.dot(c, plane_norms.T)\n",
    "a_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dot = a_dot.astype(int)\n",
    "b_dot = b_dot.astype(int)\n",
    "c_dot = c_dot.astype(int)\n",
    "a_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0011': [0], '1011': [1], '1010': [2]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectors = [a_dot, b_dot, c_dot]\n",
    "buckets = {}\n",
    "i = 0\n",
    "\n",
    "for i in range(len(vectors)):\n",
    "    # convert from array to string\n",
    "    hash_str = ''.join(vectors[i].astype(str))\n",
    "    # create bucket if it doesn't exist\n",
    "    if hash_str not in buckets.keys():\n",
    "        buckets[hash_str] = []\n",
    "    # add vector position to bucket\n",
    "    buckets[hash_str].append(i)\n",
    "\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(image_path, device):\n",
    "    image_tensor = T.ToTensor()(Image.open(image_path))\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    # print(image_tensor.shape)\n",
    "    # input_images = image_tensor.to(device)\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embedding_array = []\n",
    "for images in image_files:\n",
    "        image_tensor = load_tensor(images,device)\n",
    "        with torch.no_grad():\n",
    "                image_embedding = encoder(image_tensor).cpu().detach().numpy()\n",
    "        flattened_embedding = image_embedding.reshape((image_embedding.shape[0], -1))\n",
    "        image_embedding_array.append(flattened_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_binary(n):\n",
    "    total = 1 << n\n",
    "    print(f\"{total} possible combinations\")\n",
    "    combinations = []\n",
    "    for i in range(total):\n",
    "        # get binary representation of integer\n",
    "        b = bin(i)[2:]\n",
    "        # pad zeros to start of binary representtion\n",
    "        b = '0' * (n - len(b)) + b\n",
    "        b = [int(i) for i in b]\n",
    "        combinations.append(b)\n",
    "    return combinations\n",
    "\n",
    "class RandomProjection:\n",
    "    # initialize what will be the buckets\n",
    "    buckets = {}\n",
    "    # initialize counter\n",
    "    counter = 0\n",
    "\n",
    "    def __init__(self, nbits, d):\n",
    "        self.nbits = nbits\n",
    "        self.d = d\n",
    "        # create our hyperplane normal vecs for splitting data\n",
    "        self.plane_norms = np.random.rand(d, nbits) - .5\n",
    "        print(f\"Initialized {self.plane_norms.shape[1]} hyperplane normal vectors.\")\n",
    "        # add every possible combination to hashes attribute as numpy array\n",
    "        self.hashes = all_binary(nbits)\n",
    "        # and add each as a key to the buckets dictionary\n",
    "        for hash_code in self.hashes:\n",
    "            # convert to string\n",
    "            hash_code = ''.join([str(i) for i in hash_code])\n",
    "            self.buckets[hash_code] = []\n",
    "        # convert self.hashes to numpy array\n",
    "        self.hashes = np.stack(self.hashes)\n",
    "\n",
    "    def get_binary(self, vec):\n",
    "        # calculate nbits dot product values\n",
    "        direction = np.dot(vec, self.plane_norms)\n",
    "        # find positive direction (>0) and negative direction (<=0)\n",
    "        direction = direction > 0\n",
    "        # convert boolean array to integer strings\n",
    "        binary_hash = direction.astype(int)\n",
    "        return binary_hash\n",
    "        \n",
    "    def hash_vec(self, vec, show=False):\n",
    "        # generate hash\n",
    "        binary_hash = self.get_binary(vec)\n",
    "        # convert to string format for dictionary\n",
    "        binary_hash = ''.join(binary_hash.astype(str))\n",
    "        # add ID to buckets dictionary\n",
    "        self.buckets[binary_hash].append(self.counter)\n",
    "        if show:\n",
    "            print(f\"{self.counter}: {''.join(binary_hash)}\")\n",
    "        # increment counter\n",
    "        self.counter += 1\n",
    "    \n",
    "    def hamming(self, hashed_vec):\n",
    "        # get hamming distance between query vec and all buckets in self.hashes\n",
    "        hamming_dist = np.count_nonzero(hashed_vec != self.hashes, axis=1).reshape(-1, 1)\n",
    "        # add hash values to each row\n",
    "        hamming_dist = np.concatenate((self.hashes, hamming_dist), axis=1)\n",
    "        # sort based on distance\n",
    "        hamming_dist = hamming_dist[hamming_dist[:, -1].argsort()]\n",
    "        return hamming_dist\n",
    "    \n",
    "    def top_k(self, vec, k=5):\n",
    "        # generate hash\n",
    "        binary_hash = self.get_binary(vec)\n",
    "        # calculate hamming distance between all vectors\n",
    "        hamming_dist = self.hamming(binary_hash)\n",
    "        # loop through each bucket until we have k or more vector IDs\n",
    "        vec_ids = []\n",
    "        for row in hamming_dist:\n",
    "            str_hash = ''.join(row[:-1].astype(str))\n",
    "            bucket_ids = self.buckets[str_hash]\n",
    "            vec_ids.extend(bucket_ids)\n",
    "            if len(vec_ids) >= k:\n",
    "                vec_ids = vec_ids[:k]\n",
    "                break\n",
    "        # return top k IDs\n",
    "        return vec_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# now define a function to read the fvecs file format of Sift1M dataset\n",
    "def read_fvecs(fp):\n",
    "    a = np.fromfile(fp, dtype='int32')\n",
    "    d = a[0]\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')\n",
    "\n",
    "# 1M samples\n",
    "wb = read_fvecs('../../../data/sift/sift_base.fvecs')\n",
    "# queries\n",
    "xq = read_fvecs('../../../data/sift/sift_query.fvecs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def all_binary(n):\n",
    "    total = 1 << n\n",
    "    print(f\"{total} possible combinations\")\n",
    "    combinations = []\n",
    "    for i in range(total):\n",
    "        # get binary representation of integer\n",
    "        b = bin(i)[2:]\n",
    "        # pad zeros to start of binary representtion\n",
    "        b = '0' * (n - len(b)) + b\n",
    "        b = [int(i) for i in b]\n",
    "        combinations.append(b)\n",
    "    return combinations\n",
    "\n",
    "class RandomProjection:\n",
    "    # initialize what will be the buckets\n",
    "    buckets = {}\n",
    "    # initialize counter\n",
    "    counter = 0\n",
    "\n",
    "    def __init__(self, nbits, d):\n",
    "        self.nbits = nbits\n",
    "        self.d = d\n",
    "        # create our hyperplane normal vecs for splitting data\n",
    "        np.random.seed(10)\n",
    "        self.plane_norms = np.random.rand(d, nbits) - .5\n",
    "        print(f\"Initialized {projection.plane_norms.shape[1]} hyperplane normal vectors.\")\n",
    "        # add every possible combination to hashes attribute as numpy array\n",
    "        self.hashes = all_binary(nbits)\n",
    "        # and add each as a key to the buckets dictionary\n",
    "        for hash_code in self.hashes:\n",
    "            # convert to string\n",
    "            hash_code = ''.join([str(i) for i in hash_code])\n",
    "            self.buckets[hash_code] = []\n",
    "        # convert self.hashes to numpy array\n",
    "        self.hashes = np.stack(self.hashes)\n",
    "\n",
    "    def get_binary(self, vec):\n",
    "        # calculate nbits dot product values\n",
    "        direction = np.dot(vec, projection.plane_norms)\n",
    "        # find positive direction (>0) and negative direction (<=0)\n",
    "        direction = direction > 0\n",
    "        # convert boolean array to integer strings\n",
    "        binary_hash = direction.astype(int)\n",
    "        return binary_hash\n",
    "        \n",
    "    def hash_vec(self, vec, show=False):\n",
    "        # generate hash\n",
    "        binary_hash = self.get_binary(vec)\n",
    "        # convert to string format for dictionary\n",
    "        binary_hash = ''.join(binary_hash.astype(str))\n",
    "        # add ID to buckets dictionary\n",
    "        self.buckets[binary_hash].append(self.counter)\n",
    "        if show:\n",
    "            print(f\"{self.counter}: {''.join(binary_hash)}\")\n",
    "        # increment counter\n",
    "        self.counter += 1\n",
    "    \n",
    "    def hamming(self, hashed_vec):\n",
    "        # get hamming distance between query vec and all buckets in self.hashes\n",
    "        hamming_dist = np.count_nonzero(hashed_vec != projection.hashes, axis=1).reshape(-1, 1)\n",
    "        # add hash values to each row\n",
    "        hamming_dist = np.concatenate((projection.hashes, hamming_dist), axis=1)\n",
    "        # sort based on distance\n",
    "        hamming_dist = hamming_dist[hamming_dist[:, -1].argsort()]\n",
    "        return hamming_dist\n",
    "    \n",
    "    def top_k(self, vec, k=5):\n",
    "        # generate hash\n",
    "        binary_hash = self.get_binary(vec)\n",
    "        # calculate hamming distance between all vectors\n",
    "        hamming_dist = self.hamming(binary_hash)\n",
    "        # loop through each bucket until we have k or more vector IDs\n",
    "        vec_ids = []\n",
    "        for row in hamming_dist:\n",
    "            str_hash = ''.join(row[:-1].astype(str))\n",
    "            bucket_ids = self.buckets[str_hash]\n",
    "            vec_ids.extend(bucket_ids)\n",
    "            if len(vec_ids) >= k:\n",
    "                vec_ids = vec_ids[:k]\n",
    "                break\n",
    "        # return top k IDs\n",
    "        return vec_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embedding_array_new = []\n",
    "# encoder.load_state_dict(torch.load(ENCODER_MODEL_PATH, map_location=device))\n",
    "# encoder.eval()\n",
    "# encoder.to(device)\n",
    "\n",
    "# # Loads the embedding\n",
    "# embedding = np.load(EMBEDDING_PATH)\n",
    "for images in image_files:\n",
    "        image_tensor = load_tensor(images,device)\n",
    "        with torch.no_grad():\n",
    "                image_embedding = encoder(image_tensor).cpu().detach().numpy()\n",
    "        flattened_embedding = image_embedding.reshape((image_embedding.shape[0], -1))\n",
    "        image_embedding_array_new.append(flattened_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embedding_array_new[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 6 hyperplane normal vectors.\n",
      "64 possible combinations\n"
     ]
    }
   ],
   "source": [
    "projection = RandomProjection(6, image_embedding_array[1].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 6)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection.plane_norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 001010\n"
     ]
    }
   ],
   "source": [
    "projection.hash_vec(image_embedding_array[6666][0], show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 576)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embedding_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(image_embedding_array)-1):\n",
    "    projection.hash_vec(image_embedding_array[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 6, 7, 9, 11, 12]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10 = projection.top_k(image_embedding_array[0][0], k=10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = []\n",
    "for i in top_10:\n",
    "    similar_images.append(image_embedding_array[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "for images in image_embedding_array:\n",
    "    all_images.append(np.asarray(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732129"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = cosine_similarity(np.asarray(similar_images), [image_embedding_array[0][0]])\n",
    "np.mean(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9390613"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = cosine_similarity(all_images, [image_embedding_array[0][0]])\n",
    "np.mean(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_images = []\n",
    "for i in range(10):\n",
    "    random_image = random.choice(all_images)\n",
    "    random_images.append(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_check(query_vecs):\n",
    "    results = {'xq': [], 'wb': []}\n",
    "    for xq in query_vecs:\n",
    "        top_10 = projection.top_k(xq, k=10)\n",
    "        considered_images = []\n",
    "        for i in top_10:\n",
    "            considered_images.append(all_images[i])\n",
    "        cos = cosine_similarity(considered_images, [xq])\n",
    "        cos = np.mean(cos)\n",
    "        results['xq'].append(cos)\n",
    "        cos = cosine_similarity(all_images, [xq])\n",
    "        cos = np.mean(cos)    \n",
    "        results['wb'].append(cos)\n",
    "    print(f\"random images: {np.mean(results['xq'])}\")\n",
    "    print(f\"all images: {np.mean(results['wb'])}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random images: 0.8754922151565552\n",
      "all images: 0.9331744909286499\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = sim_check(random_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Initialized 2 hyperplane normal vectors.\n",
      "4 possible combinations\n",
      "random images: 0.8812974095344543\n",
      "all images: 0.9331744909286499\n",
      "Initialized 4 hyperplane normal vectors.\n",
      "16 possible combinations\n",
      "random images: 0.8888794183731079\n",
      "all images: 0.9331744909286499\n",
      "Initialized 8 hyperplane normal vectors.\n",
      "256 possible combinations\n",
      "random images: 0.8812181353569031\n",
      "all images: 0.9331744909286499\n",
      "Initialized 12 hyperplane normal vectors.\n",
      "4096 possible combinations\n",
      "random images: 0.9493486285209656\n",
      "all images: 0.9331744909286499\n",
      ".\n",
      "Initialized 2 hyperplane normal vectors.\n",
      "4 possible combinations\n",
      "random images: 0.8812974095344543\n",
      "all images: 0.9331744909286499\n",
      "Initialized 4 hyperplane normal vectors.\n",
      "16 possible combinations\n",
      "random images: 0.8761838674545288\n",
      "all images: 0.9331744909286499\n",
      "Initialized 8 hyperplane normal vectors.\n",
      "256 possible combinations\n",
      "random images: 0.8937332034111023\n",
      "all images: 0.9331744909286499\n",
      "Initialized 12 hyperplane normal vectors.\n",
      "4096 possible combinations\n",
      "random images: 0.9572697877883911\n",
      "all images: 0.9331744909286499\n",
      ".\n",
      "Initialized 2 hyperplane normal vectors.\n",
      "4 possible combinations\n",
      "random images: 0.9181534647941589\n",
      "all images: 0.9331744909286499\n",
      "Initialized 4 hyperplane normal vectors.\n",
      "16 possible combinations\n",
      "random images: 0.8972187042236328\n",
      "all images: 0.9331744909286499\n",
      "Initialized 8 hyperplane normal vectors.\n",
      "256 possible combinations\n",
      "random images: 0.8812974095344543\n",
      "all images: 0.9331744909286499\n",
      "Initialized 12 hyperplane normal vectors.\n",
      "4096 possible combinations\n",
      "random images: 0.942815899848938\n",
      "all images: 0.9331744909286499\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testing = pd.DataFrame({\n",
    "    'nbits': [],\n",
    "    'random_images_sim': []\n",
    "})\n",
    "\n",
    "num_vecs = 10\n",
    "\n",
    "for epoch in range(3):\n",
    "    print('.')\n",
    "    for nbits in [2, 4, 8, 12]:\n",
    "        # initialize projection object\n",
    "        projection = RandomProjection(nbits, np.asarray(all_images).shape[1])\n",
    "        # add all our vectors\n",
    "        for i in range(len(all_images)-1):\n",
    "            projection.hash_vec(all_images[i])\n",
    "        # get results from sim_check\n",
    "        results = sim_check(random_images[:num_vecs])\n",
    "        testing = testing.append(pd.DataFrame({\n",
    "            'nbits': [nbits]*num_vecs,\n",
    "            'random_images_sim': results['xq']\n",
    "        }), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
