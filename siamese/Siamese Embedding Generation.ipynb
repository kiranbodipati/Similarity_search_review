{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0afd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3dff7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0e431d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNetwork(\n",
       "  (cnn1): Sequential(\n",
       "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout2d(p=0.2, inplace=False)\n",
       "    (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Dropout2d(p=0.2, inplace=False)\n",
       "    (10): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (11): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Dropout2d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=500, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=200, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('best_model.pt', 'rb') as f:\n",
    "    model = torch.load(f, map_location=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "550cc8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec9a6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../geological_similarity\\andesite\\012L6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../geological_similarity\\andesite\\01ITR.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../geological_similarity\\andesite\\01LQQ.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../geological_similarity\\andesite\\0230P.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../geological_similarity\\andesite\\02741.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      location  label\n",
       "0  ../geological_similarity\\andesite\\012L6.jpg      0\n",
       "1  ../geological_similarity\\andesite\\01ITR.jpg      0\n",
       "2  ../geological_similarity\\andesite\\01LQQ.jpg      0\n",
       "3  ../geological_similarity\\andesite\\0230P.jpg      0\n",
       "4  ../geological_similarity\\andesite\\02741.jpg      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_locs = pd.read_csv('geo_image_locations.csv')\n",
    "image_locs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57763de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_img = Image.open(image_locs['location'][0]).convert(\"RGB\")\n",
    "transform = T.ToTensor()\n",
    "dummy_img = transform(dummy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1763572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(dummy_img.size())\n",
    "dummy_img = dummy_img.unsqueeze(0)\n",
    "print(dummy_img.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3ef64ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  904.2946,   131.8694,    -6.5602,    -1.8539,    40.2483,   551.6593,\n",
      "           500.0600,   150.3830,  -514.0599,   281.0977,   826.2490,   256.2123,\n",
      "           219.1050,  -288.6044,   585.0936,  -126.9068,   255.2296,   -40.3754,\n",
      "           143.6588,   119.0904,  -184.0937,    59.4010,    30.3005,   427.7617,\n",
      "           122.0748,  -266.1637,   -45.3790,   686.5146,   238.9694,   188.5269,\n",
      "           322.2386,  -109.8788,    10.4488,   343.5501,   727.5720,   569.9228,\n",
      "          -346.0932,   407.5990,  -282.3198, -1009.6946,  -316.6801,  -469.9283,\n",
      "           188.5190,  -639.3193,   190.0857,    89.0589,  -322.3192,  -220.8505,\n",
      "          -806.3140,  -242.7900]], device='cuda:0')\n",
      "torch.Size([1, 50])\n",
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dummy_img = dummy_img.to(device)\n",
    "    v1, v2 = model(dummy_img, dummy_img)\n",
    "print(v1)\n",
    "print(v1.size())\n",
    "print(cos(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53a53858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  904.29456  ,   131.86935  ,    -6.560202 ,    -1.8538573,\n",
       "           40.24828  ,   551.6593   ,   500.05997  ,   150.38301  ,\n",
       "         -514.0599   ,   281.09772  ,   826.24896  ,   256.21228  ,\n",
       "          219.105    ,  -288.60437  ,   585.09357  ,  -126.90682  ,\n",
       "          255.22958  ,   -40.375412 ,   143.65877  ,   119.090416 ,\n",
       "         -184.0937   ,    59.40103  ,    30.300495 ,   427.7617   ,\n",
       "          122.07479  ,  -266.16373  ,   -45.379    ,   686.51465  ,\n",
       "          238.9694   ,   188.52693  ,   322.23862  ,  -109.87884  ,\n",
       "           10.448791 ,   343.5501   ,   727.57196  ,   569.9228   ,\n",
       "         -346.09323  ,   407.59903  ,  -282.3198   , -1009.6946   ,\n",
       "         -316.68015  ,  -469.92825  ,   188.51903  ,  -639.3193   ,\n",
       "          190.08571  ,    89.05893  ,  -322.31918  ,  -220.85052  ,\n",
       "         -806.314    ,  -242.79004  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_embedding = v1.cpu().detach().numpy()\n",
    "temp_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b70e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in: 56.27270579338074 seconds\n",
      "Average time: 0.0018758819185739294 seconds per embedding\n"
     ]
    }
   ],
   "source": [
    "embeddings = None\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    for i in range(len(image_locs)):\n",
    "        img = Image.open(image_locs['location'][i]).convert(\"RGB\")\n",
    "        img = transform(img)\n",
    "        img = img.unsqueeze(0)  # adds dimension at 0 to represent batch size of 1\n",
    "        img = img.to(device)\n",
    "        v1, v2 = model(img, img)\n",
    "        if embeddings==None:\n",
    "            embeddings=v1\n",
    "        else:\n",
    "            embeddings = torch.cat((embeddings, v1), 0)\n",
    "    end = time.time()\n",
    "    print(\"Completed in: {} seconds\".format((end-start)))\n",
    "    print(\"Average time: {} seconds per embedding\".format((end-start)/len(image_locs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01896006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29998, 50])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b2a3abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29998, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_embedding = embeddings.cpu().detach().numpy()\n",
    "numpy_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34cf0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"geo_siamese_embeds.npy\", numpy_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3328d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
